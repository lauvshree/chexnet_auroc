{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shutil\n",
    "import warnings\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from imgaug import augmenters as iaa\n",
    "import os\n",
    "import pickle\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as kb\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization, Input, Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.densenet import DenseNet121\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thread safe generators with augmentation\n",
    "class AugmentedImageSequence(Sequence):\n",
    "    def __init__(self, dataset_file, class_names, source_dir, batch_size = 8, target_size = (224,224),\n",
    "                augmenter = None, verbose = 0, steps = None, shuffle_on_epoch_end = True, random_state = 3):\n",
    "        self.dataset_df = pd.read_csv(dataset_file)\n",
    "        self.source_dir = source_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.augmenter = augmenter\n",
    "        self.verbose = verbose\n",
    "        self.shuffle = shuffle_on_epoch_end\n",
    "        self.random_state = random_state\n",
    "        self.class_names = class_names\n",
    "        self.prepare_dataset()\n",
    "        if steps is None:\n",
    "            self.steps = int(np.ceil(len(self.x_path) / float(self.batch_size)))\n",
    "        else:\n",
    "            self.steps = int(steps)\n",
    "        \n",
    "    def __bool__(self):\n",
    "        return True\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x_path = self.x_path[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = np.asarray([self.load_image(x_path) for x_path in batch_x_path])\n",
    "        batch_x = self.transform_batch_images(batch_x)\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def load_image(self, image_file):\n",
    "        image_path = os.path.join(self.source_dir, image_file)\n",
    "        image = Image.open(image_path)\n",
    "        image_array = np.asarray(image.convert(\"RGB\"))\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        img_temp = np.zeros((image_array.shape[0],image_array.shape[1],image_array.shape[2]))\n",
    "\n",
    "        for i in range (3):\n",
    "            img_temp[:,:,i] = clahe.apply(image_array[:,:,i])\n",
    "\n",
    "        image_array = img_temp / 255.\n",
    "        image_array = resize(image_array, self.target_size)\n",
    "        return image_array\n",
    "\n",
    "    def transform_batch_images(self, batch_x):\n",
    "        if self.augmenter is not None:\n",
    "            batch_x = self.augmenter.augment_images(batch_x)\n",
    "        imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "        imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "        batch_x = (batch_x - imagenet_mean) / imagenet_std\n",
    "        return batch_x\n",
    "\n",
    "    def get_y_true(self):\n",
    "        if self.shuffle:\n",
    "            raise ValueError(\"\"\"\n",
    "            You're trying run get_y_true() when generator option 'shuffle_on_epoch_end' is True.\n",
    "            \"\"\")\n",
    "        return self.y[:self.steps*self.batch_size, :]\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        df = self.dataset_df.sample(frac=1., random_state=self.random_state)\n",
    "        self.x_path, self.y = df[\"Image_Location\"].values, df[self.class_names].values\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.random_state += 1\n",
    "            self.prepare_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_counts(output_dir, dataset, class_names):\n",
    "    df = pd.read_csv(os.path.join(output_dir, f\"{dataset}.csv\"))\n",
    "    total_count = df.shape[0]\n",
    "    labels = df[class_names].values\n",
    "    positive_counts = np.sum(labels, axis=0)\n",
    "    class_positive_counts = dict(zip(class_names, positive_counts))\n",
    "    return total_count, class_positive_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section calculates the AUROC values for the validation/dev set\n",
    "class MultipleClassAUROC(Callback):\n",
    "    \"\"\"\n",
    "    Monitor mean AUROC and update model\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence, class_names, output_path, stats=None, workers=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.sequence = sequence\n",
    "        self.workers = workers\n",
    "        self.class_names = class_names\n",
    "        self.output_path = output_path\n",
    "        \n",
    "        self.best_auroc_log_path = os.path.join(output_path, \"best_auroc.log\")\n",
    "        self.stats_output_path = os.path.join(output_path, \"training_stats.json\")\n",
    "        # for resuming previous training\n",
    "        if stats:\n",
    "            self.stats = stats\n",
    "        else:\n",
    "            self.stats = {\"best_mean_auroc\": 0}\n",
    "\n",
    "        # aurocs log\n",
    "        self.aurocs = {}\n",
    "        for c in self.class_names:\n",
    "            self.aurocs[c] = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        Calculate the average AUROC and save the best model weights according\n",
    "        to this metric.\n",
    "\n",
    "        \"\"\"\n",
    "        print(\"\\n*********************************\")\n",
    "        self.stats[\"lr\"] = float(kb.eval(self.model.optimizer.lr))\n",
    "        print(f\"current learning rate: {self.stats['lr']}\")\n",
    "\n",
    "        \"\"\"\n",
    "        y_hat shape: (#samples, len(class_names))\n",
    "        y: [(#samples, 1), (#samples, 1) ... (#samples, 1)]\n",
    "        \"\"\"\n",
    "        y_hat = self.model.predict_generator(self.sequence, workers=self.workers)\n",
    "        y = self.sequence.get_y_true()\n",
    "\n",
    "        print(f\"*** epoch#{epoch + 1} dev auroc ***\")\n",
    "        current_auroc = []\n",
    "        for i in range(len(self.class_names)):\n",
    "            try:\n",
    "                score = roc_auc_score(y[:, i], y_hat[:, i])\n",
    "            except ValueError:\n",
    "                score = 0\n",
    "            self.aurocs[self.class_names[i]].append(score)\n",
    "            current_auroc.append(score)\n",
    "            print(f\"{i+1}. {self.class_names[i]}: {score}\")\n",
    "        print(\"*********************************\")\n",
    "\n",
    "        # customize your multiple class metrics here\n",
    "        mean_auroc = np.mean(current_auroc)\n",
    "        print(f\"mean auroc: {mean_auroc}\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = iaa.Sequential([iaa.OneOf([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Affine(rotate=(-10, 10)),\n",
    "        iaa.Noop(),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 1.0)),\n",
    "        iaa.Affine(shear=(-16, 16)),\n",
    "        iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)})\n",
    "    ])],random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 512\n",
    "batch_size = 4\n",
    "class_names = \"Normal,Pneumonia\"\n",
    "class_names = class_names.split(\",\")\n",
    "output_dir = \"../output/\"\n",
    "image_dir = \"../data/images/\"\n",
    "epochs = 20\n",
    "init_lr = 1e-4\n",
    "min_lr = 1e-8\n",
    "csv_dir = \"../data/\"\n",
    "generator_workers = 8\n",
    "use_trained_model_weights = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_trained_model_weights:\n",
    "    # resuming mode\n",
    "    print(\"** use trained model weights **\")\n",
    "    # load training status for resuming\n",
    "    training_stats_file = os.path.join(output_dir, \"training_stats.json\")\n",
    "    if os.path.isfile(training_stats_file):\n",
    "        # TODO: add loading previous learning rate?\n",
    "        training_stats = json.load(open(training_stats_file))\n",
    "    else:\n",
    "        training_stats = {}\n",
    "else:\n",
    "    # start over\n",
    "    training_stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts, train_pos_counts = get_sample_counts(csv_dir, \"train\", class_names)\n",
    "val_counts, val_pos_counts = get_sample_counts(csv_dir, \"val\", class_names)\n",
    "test_counts, test_pos_counts = get_sample_counts(csv_dir, \"test_onehot\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_counts)\n",
    "print(train_pos_counts)\n",
    "print(val_counts)\n",
    "print(val_pos_counts)\n",
    "print(test_counts)\n",
    "print(test_pos_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = int(train_counts / batch_size)\n",
    "validation_steps = int(val_counts / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "def chexnet_model(input_shape, num_classes):\n",
    "    input_tensor = Input(shape = input_shape, name = 'input_1')\n",
    "    \n",
    "    base_model = DenseNet121(include_top = False, weights = 'imagenet', input_shape = input_shape, pooling = \"avg\")\n",
    "    X = base_model(input_tensor)\n",
    "    X = Dropout(0.2)(X)\n",
    "    output = Dense(num_classes, activation = 'sigmoid', name = 'dense_1', kernel_initializer = 'he_normal')(X)\n",
    "    model = Model(input_tensor, output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we train on the images in this section\n",
    "train_sequence = AugmentedImageSequence(\n",
    "            dataset_file=os.path.join(csv_dir, \"train.csv\"),\n",
    "            class_names=class_names,\n",
    "            source_dir=image_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_size, image_size),\n",
    "            augmenter=augmenter,\n",
    "            steps=train_steps)\n",
    "\n",
    "validation_sequence = AugmentedImageSequence(\n",
    "            dataset_file=os.path.join(csv_dir, \"val.csv\"),\n",
    "            class_names=class_names,\n",
    "            source_dir=image_dir,\n",
    "            batch_size=batch_size,\n",
    "            target_size=(image_size, image_size),\n",
    "            augmenter=augmenter,\n",
    "            steps=validation_steps,\n",
    "            shuffle_on_epoch_end=False)\n",
    "\n",
    "checkpoint = ModelCheckpoint('../models/chexnet_v4_rsna_{epoch:02d}.h5', verbose = 1, save_weights_only = True, period = 1)\n",
    "\n",
    "auroc = MultipleClassAUROC(\n",
    "            sequence=validation_sequence,\n",
    "            class_names=class_names,\n",
    "            output_path=output_dir,\n",
    "            stats=training_stats,\n",
    "            workers=generator_workers)\n",
    "callbacks = [checkpoint,TensorBoard(log_dir=os.path.join(output_dir, \"logs\"), batch_size=batch_size),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3,verbose=1, mode=\"min\", min_lr=min_lr), auroc]\n",
    "\n",
    "\n",
    "model = chexnet_model(input_shape = (image_size,image_size,3), num_classes = len(class_names))\n",
    "\n",
    "#model.summary() 7 mil params\n",
    "\n",
    "#change the values below based on what you want to do. warmup is only required the first time you start training.\n",
    "#load saved weights if you want to continue training from a previously stopped point.\n",
    "train_mode = True\n",
    "warmup_model = True\n",
    "load_weights = False\n",
    "\n",
    "if train_mode:\n",
    "    \n",
    "    #load previously saved weights if you want to continue training\n",
    "    if load_weights:\n",
    "        model.load_weights('../models/chexnet_v3_rsna_04.h5', by_name = True)\n",
    "    \n",
    "    if warmup_model:\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        model.layers[-1].trainable = True\n",
    "        \n",
    "        model.compile(loss = 'binary_crossentropy', optimizer=Adam(lr = init_lr))\n",
    "\n",
    "        model.fit_generator(generator = train_sequence, steps_per_epoch = train_steps, epochs=1, verbose=1, \n",
    "                            workers=generator_workers,shuffle = False)\n",
    "    \n",
    "     #now train all the layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=Adam(lr = init_lr))\n",
    "\n",
    "    history = model.fit_generator(generator = train_sequence, steps_per_epoch = train_steps, epochs=epochs, verbose=1, \n",
    "                        workers=generator_workers,shuffle = False, validation_data=validation_sequence,\n",
    "                        validation_steps=validation_steps, callbacks=callbacks)\n",
    "\n",
    "with open(os.path.join(output_dir, \"history.pkl\"), \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"history\": history.history,\n",
    "                \"auroc\": auroc.aurocs,\n",
    "            }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from here on generates the cam output and auroc scores\n",
    "output_dir_test = \"../output/cam/\"\n",
    "image_source_dir = \"../data/images/\"\n",
    "image_dimension = 512\n",
    "\n",
    "\n",
    "# CAM config\n",
    "bbox_list_file = \"../data/test.csv\"\n",
    "\n",
    "print(\"** load model **\")\n",
    "model = chexnet_model(input_shape = (image_dimension,image_dimension,3), num_classes = len(class_names))\n",
    "model.load_weights('../models/chexnet_v4_rsna_03.h5', by_name = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the code in this section generates the cam images.\n",
    "df_images = pd.read_csv(bbox_list_file) \n",
    "\n",
    "#for the image index below change to a specific number manually or generate images based on random index values\n",
    "img_index = 226 #np.random.randint(0, 1450)\n",
    "print(img_index)\n",
    "file_name = df_images[\"Image_Location\"][img_index]\n",
    "print(file_name)\n",
    "\n",
    "# draw bbox with labels\n",
    "# draw bbox with labels\n",
    "img_ori = Image.open(os.path.join(image_source_dir, file_name))\n",
    "img_ori = np.asarray(img_ori.convert(\"RGB\"))\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img_temp = np.zeros((img_ori.shape[0],img_ori.shape[1],img_ori.shape[2]))\n",
    "\n",
    "for i in range (3):\n",
    "    img_temp[:,:,i] = clahe.apply(img_ori[:,:,i])\n",
    "\n",
    "img_ori = img_temp / 255.\n",
    "img_ori = resize(img_ori, (512,512))\n",
    "\n",
    "img_transformed = np.array([img_ori])\n",
    "\n",
    "label = df_images[\"Label\"][img_index]\n",
    "\n",
    "index = class_names.index(label)\n",
    "\n",
    "# CAM overlay\n",
    "class_weights = model.layers[-1].get_weights()[0]\n",
    "\n",
    "layer_model_1 = Model(inputs=model.layers[1].layers[0].input, outputs = model.layers[1].layers[-2].output)\n",
    "\n",
    "print(img_transformed.shape)\n",
    "conv_outputs = layer_model_1.predict(img_transformed)[0]\n",
    "predictions = model.predict(img_transformed)[0]\n",
    "print(predictions)\n",
    "pred_name = class_names[np.argmax(predictions)]\n",
    "print(pred_name)\n",
    "output_path = os.path.join(output_dir_test, f\"{label}_{pred_name}_{img_index}_{file_name}\")\n",
    "\n",
    "# Create the class activation map.\n",
    "cam = np.zeros(dtype=np.float32, shape=(conv_outputs.shape[:2]))\n",
    "for i, w in enumerate(class_weights[index]):\n",
    "    cam += w * conv_outputs[:, :, i]\n",
    "\n",
    "cam /= np.max(cam)\n",
    "cam = cv2.resize(cam, img_ori.shape[:2])\n",
    "heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "heatmap[np.where(cam < 0.2)] = 0\n",
    "img = heatmap*0.5 + img_ori\n",
    "\n",
    "# add label & rectangle\n",
    "ratio = 1\n",
    "\n",
    "if not np.isnan(df_images[\"x1\"][img_index]):\n",
    "    x1 = int(df_images[\"x1\"][img_index] * ratio)\n",
    "    y1 = int(df_images[\"y1\"][img_index] * ratio)\n",
    "    x2 = int((df_images[\"x2\"][img_index] ) * ratio)\n",
    "    y2 = int((df_images[\"y2\"][img_index] ) * ratio)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    cv2.putText(img, text=label, org=(5, 20), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=0.8, color=(0, 0, 255), thickness=1)\n",
    "cv2.imwrite(output_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to calculate ytrue and ypred on test set\n",
    "\n",
    "df_images = pd.read_csv(bbox_list_file)\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_raw = []\n",
    "\n",
    "for img_index in range(df_images.shape[0]): \n",
    "\n",
    "    file_name = df_images[\"Image_Location\"][img_index]\n",
    "\n",
    "    # draw bbox with labels\n",
    "    img_ori = Image.open(os.path.join(image_source_dir, file_name))\n",
    "    img_ori = np.asarray(img_ori.convert(\"RGB\"))\n",
    "           \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    img_temp = np.zeros((img_ori.shape[0],img_ori.shape[1],img_ori.shape[2]))\n",
    "\n",
    "    for i in range (3):\n",
    "        img_temp[:,:,i] = clahe.apply(img_ori[:,:,i])\n",
    "\n",
    "\n",
    "    img_ori = img_temp / 255.\n",
    "    img_ori = resize(img_ori, (512,512))\n",
    "    #imshow(img_ori)\n",
    "\n",
    "    label = df_images[\"Label\"][img_index]\n",
    "\n",
    "    index = class_names.index(label)\n",
    "    \n",
    "    if index == 0:\n",
    "        index = [1, 0]\n",
    "    elif index == 1:\n",
    "        index = [0, 1]\n",
    "        \n",
    "    y_true.append(index)\n",
    "    \n",
    "   # img_transformed = resize(img_ori, (image_dimension,image_dimension,3))\n",
    "    img_transformed = np.array([img_ori])\n",
    "\n",
    "    predictions = model.predict(img_transformed)[0]\n",
    "    y_pred_raw.append(predictions)\n",
    "    \n",
    "    if np.argmax(predictions) == 0:\n",
    "        y_pred.append([1, 0])\n",
    "    else:\n",
    "        y_pred.append([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the auroc score in this section from ytrue and ypred\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    try:\n",
    "        score = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "    except ValueError:\n",
    "        score = 0\n",
    "    print(f\"{i+1}. {class_names[i]}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
